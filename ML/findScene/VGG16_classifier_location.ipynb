{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtP5lglkbR-p"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import utils as np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from keras.applications import vgg16\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/sample_data/\"\n",
        "zip_dir = base_dir + \"zipImg\"\n",
        "zip_path = base_dir + \"zipImg/images.zip\"\n",
        "image_dir = base_dir + \"images\"\n",
        "dataset_dir = base_dir + \"dataset\"\n",
        "dataset_path = base_dir + 'dataset/dataset.xlsx'\n",
        "\n",
        "img_df = pd.read_excel(dataset_path)"
      ],
      "metadata": {
        "id": "og7qat1Grsqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(base_dir)\n",
        "\n",
        "if not os.path.exists(zip_dir):\n",
        "  os.mkdir(\"zipImg\")\n",
        "\n",
        "if not os.path.exists(image_dir):\n",
        "  os.mkdir(\"images\")\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  os.mkdir(\"dataset\")"
      ],
      "metadata": {
        "id": "Oeo_ZUHMMetc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Разархивируем архив**"
      ],
      "metadata": {
        "id": "HvRDFljf2AJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zip():\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(image_dir)"
      ],
      "metadata": {
        "id": "quCjWxu_2Evd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загружаем изображения**"
      ],
      "metadata": {
        "id": "lQiXrTZSbatv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadPathsImages():\n",
        "  names = img_df['Путь']\n",
        "  paths = []\n",
        "\n",
        "  for name in names:\n",
        "    full_path = image_dir + \"/\" + str(name)\n",
        "    paths.append(full_path)\n",
        "\n",
        "  paths = np.asarray(paths)\n",
        "  return paths"
      ],
      "metadata": {
        "id": "Ljj_iQ-NbbNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(paths):\n",
        "  images = []\n",
        "\n",
        "  for path in paths:\n",
        "    #image = Image.open(path)\n",
        "    image = cv2.imread(path)\n",
        "\n",
        "    #print(image.shape)\n",
        "    #if (len(src.shape) != 3):\n",
        "      #image = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "    array = np.array(image)\n",
        "    images.append(array)\n",
        "\n",
        "  return images"
      ],
      "metadata": {
        "id": "vmqF-b_IbdL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Уменьшаем размер до 224x224 и нормализуем**"
      ],
      "metadata": {
        "id": "5snYB6f6beUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resizeImages(images):\n",
        "  reImages = []\n",
        "\n",
        "  for img in images:\n",
        "    new_img = cv2.resize(img, (224, 224))\n",
        "    new_img = new_img / 255\n",
        "    reImages.append(new_img)\n",
        "  return reImages"
      ],
      "metadata": {
        "id": "ako4zmL5bgL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Классы изображений**"
      ],
      "metadata": {
        "id": "-DkI4GEebimE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {1:'Спальня', 2:'Частный дом', 3:'Промышленный район', 4:'Кухня', 5:'Гостинная', 6:'Море', 7:'Лес', 8:\n",
        " 'Дорога', 9:'Здание', 10:'Гора',11:'Равнина', 12:'Улица', 13:'Небоскреб', 14:'Рабочий кабинет', 15:'Магазин'}"
      ],
      "metadata": {
        "id": "Xb-AHYHnbjyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загружаем метки и кодириуем по OHE**"
      ],
      "metadata": {
        "id": "KMmyT30-blRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadLabels():\n",
        "  df = pd.read_excel(dir)\n",
        "\n",
        "  labels_df = df['Метка класса']\n",
        "  labels = []\n",
        "\n",
        "  for label in labels_df:\n",
        "    # Метки идут от 1, поэтому - 1\n",
        "    labels.append(label - 1)\n",
        "\n",
        "  labels = np.array(labels)\n",
        "  label_cat = keras.utils.to_categorical(labels)\n",
        "\n",
        "  return label_cat"
      ],
      "metadata": {
        "id": "P35lz2ZnbkUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготавливаем модель**"
      ],
      "metadata": {
        "id": "daxmyc99boyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareModel():\n",
        "  vgg_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(vgg_model)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # Разблокируем все последние слои для обучения\n",
        "  vgg_model.trainable = True\n",
        "  trainable = False\n",
        "  for layer in vgg_model.layers:\n",
        "      if layer.name == 'block5_conv1':\n",
        "          trainable = True\n",
        "      layer.trainable = trainable\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "z8IieKkKboTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Компилируем и обучаем модель**"
      ],
      "metadata": {
        "id": "i7C2NiBLbsqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(model):\n",
        "  model = prepareModel()\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='val_acc', min_delta=0.0001,\n",
        "                           patience=5, verbose=1, mode='auto')\n",
        "\n",
        "  # filepath = \"model.h5\"\n",
        "  # if os.path.exists(filepath):\n",
        "  #   checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "  # else:\n",
        "  #   checkpoint = ModelCheckpoint(model, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "  # callbacks = [early_stop, checkpoint]\n",
        "\n",
        "  model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "  # model.fit(X_train, y_train, epochs=5, batch_size=64, callbacks=callbacks)\n",
        "  model.fit(X_train, y_train, epochs=15, batch_size=512)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "QCdyLJh-bsUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Оцениваем модель**"
      ],
      "metadata": {
        "id": "-VXUdhdfeZI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(model):\n",
        "  results = model.evaluate(X_test, y_test, batch_size=64)\n",
        "  print('test loss, test acc:', results)"
      ],
      "metadata": {
        "id": "Mo8YPNcjef4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Прогноз модели**"
      ],
      "metadata": {
        "id": "7PuroP2qeqtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "  image = Image.open('/content/sample_data/test.jpg')\n",
        "  image = np.array(image)\n",
        "  image = cv2.resize(image, (224, 224))\n",
        "  image = image / 255\n",
        "\n",
        "  print(X_train[0].shape)\n",
        "  print(image.shape)\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  pred = model.predict(image)\n",
        "  print(classes[np.argmax(pred)])"
      ],
      "metadata": {
        "id": "vJU0LqXveui1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(os.listdir(zip_dir)) == 0:\n",
        "  zip()\n",
        "\n",
        "paths = loadPathsImages()\n",
        "images = loadImages(paths)\n",
        "\n",
        "\n",
        "\n",
        "X = np.asarray(resizeImages(images))\n",
        "y = loadLabels()\n",
        "\n",
        "del paths\n",
        "del images\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "del X\n",
        "del y"
      ],
      "metadata": {
        "id": "_Yxv7maPbvqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = trainModel(model)"
      ],
      "metadata": {
        "id": "fTW8L0P8bxG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateModel(model)"
      ],
      "metadata": {
        "id": "Zu84uTVqnBQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}